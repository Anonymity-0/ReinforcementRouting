{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Part 1: 导入必要的库\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from env import SatelliteEnv # 使用 env1.py\n",
    "from agents.mappo_agent import MAPPOAgent \n",
    "import pandas as pd\n",
    "\n",
    "# Part 2: 初始化环境和训练参数\n",
    "# 初始化卫星环境\n",
    "env = SatelliteEnv(service_type='delay_sensitive', multi_agent=True)\n",
    "\n",
    "# 获取环境参数\n",
    "observations = env.get_observation()\n",
    "obs_sizes = [len(o['cache_states']) for o in observations] # 基于区域观察的维度\n",
    "n_agents = len(obs_sizes)  # 区域数量作为智能体数量\n",
    "action_dim = env.k_paths  # 每个智能体的动作空间\n",
    "\n",
    "# 设置训练超参数\n",
    "hidden_dim = 64 \n",
    "learning_rate = 0.001\n",
    "episodes = 1000\n",
    "steps_per_episode = 50\n",
    "batch_size = 128\n",
    "gamma = 0.99\n",
    "epsilon_start = 1.0\n",
    "epsilon_end = 0.01\n",
    "epsilon_decay = 0.995\n",
    "\n",
    "# 初始化 MAPPO 智能体\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mappo_agent = MAPPOAgent(\n",
    "    n_agents=n_agents,\n",
    "    obs_sizes=obs_sizes, \n",
    "    action_dim=action_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    learning_rate=learning_rate,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Part 3: 训练循环\n",
    "epsilon = epsilon_start\n",
    "episode_rewards = []\n",
    "metrics_history = []\n",
    "\n",
    "for episode in range(episodes):\n",
    "    observations = env.reset()\n",
    "    episode_reward = 0\n",
    "    episode_metrics = []\n",
    "    \n",
    "    for step in range(steps_per_episode):\n",
    "        # 基于 epsilon-greedy 选择动作\n",
    "        actions = mappo_agent.select_action(observations, epsilon)\n",
    "        \n",
    "        # 在环境中执行动作\n",
    "        next_observations, reward, done = env.step(actions)\n",
    "        \n",
    "        # 存储经验\n",
    "        mappo_agent.store_experience((observations, actions, reward, next_observations, done))\n",
    "        \n",
    "        # 如果经验池中有足够样本,则进行学习\n",
    "        if len(mappo_agent.replay_buffer.buffer) >= batch_size:\n",
    "            mappo_agent.update(batch_size, gamma)\n",
    "            \n",
    "        episode_reward += reward\n",
    "        observations = next_observations\n",
    "        \n",
    "        # 记录性能指标\n",
    "        if len(env.get_candidate_paths(env.src, env.dst)) > 0:\n",
    "            path = env.get_candidate_paths(env.src, env.dst)[0]\n",
    "            delay, packet_loss, delivery = env.calculate_qos_metrics(path)\n",
    "            episode_metrics.append({\n",
    "                'delay': delay,\n",
    "                'packet_loss': packet_loss, \n",
    "                'delivery': delivery\n",
    "            })\n",
    "    \n",
    "    # 更新 epsilon\n",
    "    epsilon = max(epsilon_end, epsilon * epsilon_decay)\n",
    "    \n",
    "    # 记录回合奖励\n",
    "    episode_rewards.append(episode_reward)\n",
    "    metrics_history.extend(episode_metrics)\n",
    "    \n",
    "    # 打印训练进度\n",
    "    if (episode + 1) % 10 == 0:\n",
    "        print(f'Episode {episode+1}/{episodes}')\n",
    "        print(f'Average Reward: {np.mean(episode_rewards[-10:])}')\n",
    "        print(f'Epsilon: {epsilon:.3f}')\n",
    "\n",
    "# Part 4: 可视化训练结果\n",
    "# 绘制奖励曲线\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(episode_rewards)\n",
    "plt.title('Training Rewards')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.show()\n",
    "\n",
    "# 绘制 QoS 指标变化\n",
    "metrics_df = pd.DataFrame(metrics_history)\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.plot(metrics_df['delay'])\n",
    "plt.title('End-to-End Delay')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Delay (s)')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(metrics_df['packet_loss'])\n",
    "plt.title('Packet Loss Rate')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss Rate')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(metrics_df['delivery'])\n",
    "plt.title('Delivery Rate')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Delivery Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 保存模型\n",
    "torch.save({\n",
    "    'actors': [actor.state_dict() for actor in mappo_agent.actors],\n",
    "    'critic': mappo_agent.critic.state_dict()\n",
    "}, 'mappo_model_final.pth')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
